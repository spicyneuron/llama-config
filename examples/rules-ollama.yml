# NOTE: Experimental support for Ollama

- methods: POST
  paths: ^/api/chat$
  target_path: /v1/chat/completions

  on_request:
    # Transform Ollama request to OpenAI format
    - template: |
        {
          "model": {{ toJson .model }},
          "messages": {{ toJson .messages }}
          {{- if .options.temperature }},
          "temperature": {{ .options.temperature }}
          {{- end }}
          {{- if .options.top_p }},
          "top_p": {{ .options.top_p }}
          {{- end }}
          {{- if .options.top_k }},
          "top_k": {{ .options.top_k }}
          {{- end }}
          {{- if .options.num_predict }},
          "max_tokens": {{ .options.num_predict }}
          {{- end }}
          {{- if .options.seed }},
          "seed": {{ .options.seed }}
          {{- end }}
          {{- if .options.stop }},
          "stop": {{ toJson .options.stop }}
          {{- end }}
          {{- if .options.repeat_penalty }},
          "frequency_penalty": {{ add .options.repeat_penalty -1 }}
          {{- end }}
          {{- if .format }}
            {{- if kindIs "string" .format }}
              {{- if eq .format "json" }},
          "response_format": {{ toJson (dict "type" "json_object") }}
              {{- end }}
            {{- else if kindIs "map" .format }}
              {{- if .format.type }},
          "response_format": {{ toJson (dict "type" "json_object") }}
              {{- end }}
            {{- end }}
          {{- end }}
          {{- if .tools }},
          "tools": {{ toJson .tools }}
          {{- end }}
          {{- if ne .stream nil }},
          "stream": {{ .stream }}
          {{- end }}
        }

  on_response:
    # Transform OpenAI streaming chunks to Ollama format
    # Match specifically on chunks (has delta field, not message field)
    - match_body:
        object: chat\.completion\.chunk
      template: |
        {{- $choice := index .choices 0 }}
        {{- $delta := index $choice "delta" }}
        {{- $finishReason := index $choice "finish_reason" }}
        {{- $content := "" }}
        {{- if $delta }}
          {{- with index $delta "content" }}
            {{- $content = . }}
          {{- end }}
        {{- end }}
        {
          "model": {{ toJson .model }},
          "created_at": {{ toJson (isoTime now) }},
          "message": {
            "role": "assistant",
            "content": {{ toJson $content }}
          },
          "done": {{ if $finishReason }}true{{ else }}false{{ end }}
          {{- if $finishReason }},
          "done_reason": {{ toJson $finishReason }}
          {{- end }}
        }

    # Transform OpenAI non-streaming response to Ollama format
    # Match specifically on completions (has message field, not delta field)
    - match_body:
        object: ^chat\.completion$
      template: |
        {
          "model": {{ toJson .model }},
          "created_at": {{ toJson (isoTime now) }},
          "message": {{ toJson (index .choices 0 "message") }},
          "done": true
          {{- $finishReason := index .choices 0 "finish_reason" }}
          {{- if $finishReason }},
          "done_reason": {{ toJson $finishReason }}
          {{- end }}
          {{- if .usage }}
            {{- if .usage.prompt_tokens }},
          "prompt_eval_count": {{ .usage.prompt_tokens }}
            {{- end }}
            {{- if .usage.completion_tokens }},
          "eval_count": {{ .usage.completion_tokens }}
            {{- end }}
            {{- if .usage.total_tokens }},
          "total_duration": {{ mul .usage.total_tokens 100000000 }}
            {{- end }}
          {{- end }}
        }

# Model list: Ollama â†’ OpenAI
- methods: GET
  paths: ^/api/tags$
  target_path: /v1/models

  on_response:
    # Transform OpenAI models response to Ollama tags format
    # Note: Uses realistic placeholder values for fields not available from OpenAI
    - match_body:
        object: list
      template: |
        {
          "models": [
            {{- range $i, $model := .data }}
            {{- if $i }},{{ end }}
            {
              "name": {{ toJson $model.id }},
              "modified_at": {{ toJson (isoTime now) }},
              "size": 4000000000,
              "digest": {{ toJson (uuid) }},
              "details": {
                "format": "gguf",
                "family": "llama",
                "families": null,
                "parameter_size": "7B",
                "quantization_level": "Q4_0"
              }
            }
            {{- end }}
          ]
        }
