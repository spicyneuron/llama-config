# Chat completions rules migrated from legacy-config.yml
- methods: POST
  paths: .*/chat/completions$
  target_path: /v1/chat/completions

  on_request:
    # Global override
    - merge:
        max_tokens: 1000000

    # Aliases
    - match_body:
        model: ^(default|write|cli|code)$
      merge:
        model: 357-glm4.6

    - match_body:
        model: ^(vision|utility|translate)$
      merge:
        model: 030-qwen3-vl-instruct

    - match_body:
        model: ^massive$
      merge:
        model: 671-deepseek3.1

    # Model families
    - match_body:
        model: deepseek
      merge:
        temperature: 0.6
        top_p: 0.95
        min_p: 0
      stop: true

    - match_body:
        model: gemma3
      merge:
        temperature: 1
        top_k: 64
        top_p: 0.95
        min_p: 0
      stop: true

    - match_body:
        model: glm4.6|minimax-m2
      merge:
        temperature: 1
        top_k: 40
        top_p: 0.95
        min_p: 0
      stop: true

    - match_body:
        model: glm4.5
      merge:
        temperature: 0.6
        top_p: 1
      stop: true

    - match_body:
        model: gpt|jinx
      merge:
        temperature: 1
        top_k: 0
        top_p: 1
        min_p: 0
      stop: true

    - match_body:
        model: qwen3-code
      merge:
        temperature: 0.7
        top_k: 20
        top_p: 0.8
        min_p: 0
        repeat_penalty: 1.05
      stop: true

    - match_body:
        model: qwen3-vl-instruct
      merge:
        temperature: 0.7
        top_k: 20
        top_p: 0.8
        min_p: 0
        presence_penalty: 1.5
      stop: true

    - match_body:
        model: qwen3-instruct|intern3\\.5
      merge:
        temperature: 0.7
        top_k: 20
        top_p: 0.8
        min_p: 0
      stop: true

    - match_body:
        model: qwen3-think
      merge:
        temperature: 0.6
        top_k: 20
        top_p: 0.95
        min_p: 0
      stop: true
