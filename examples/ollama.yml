proxy:
  listen: "localhost:11434"
  target: "http://localhost:8080"

rules:
  - methods: POST
    paths: ^/api/chat$
    target_path: /v1/chat/completions

    on_request:
      # Transform Ollama request to OpenAI format
      - match_body:
          options: ".*"
        template: |
          {
            "model": {{ toJson .model }},
            "messages": {{ toJson .messages }}
            {{- if .options.temperature }},
            "temperature": {{ .options.temperature }}
            {{- end }}
            {{- if .options.top_p }},
            "top_p": {{ .options.top_p }}
            {{- end }}
            {{- if .options.top_k }},
            "top_k": {{ .options.top_k }}
            {{- end }}
            {{- if .options.num_predict }},
            "max_tokens": {{ .options.num_predict }}
            {{- end }}
            {{- if .options.seed }},
            "seed": {{ .options.seed }}
            {{- end }}
            {{- if .options.stop }},
            "stop": {{ toJson .options.stop }}
            {{- end }}
            {{- if .options.repeat_penalty }},
            "frequency_penalty": {{ add .options.repeat_penalty -1 }}
            {{- end }}
            {{- if .format }}
              {{- if kindIs "string" .format }}
                {{- if eq .format "json" }},
            "response_format": {{ toJson (dict "type" "json_object") }}
                {{- end }}
              {{- else if kindIs "map" .format }}
                {{- if .format.type }},
            "response_format": {{ toJson (dict "type" "json_object") }}
                {{- end }}
              {{- end }}
            {{- end }}
            {{- if .tools }},
            "tools": {{ toJson .tools }}
            {{- end }}
            {{- if ne .stream nil }},
            "stream": {{ .stream }}
            {{- end }}
          }

    on_response:
      # Transform OpenAI streaming chunks to Ollama format
      # Match specifically on chunks (has delta field, not message field)
      - match_body:
          object: chat\.completion\.chunk
        template: |
          {{- $choice := index .choices 0 }}
          {{- $delta := index $choice "delta" }}
          {{- $finishReason := index $choice "finish_reason" }}
          {{- $content := "" }}
          {{- if $delta }}
            {{- with index $delta "content" }}
              {{- $content = . }}
            {{- end }}
          {{- end }}
          {
            "model": {{ toJson .model }},
            "created_at": {{ toJson (isoTime now) }},
            "message": {
              "role": "assistant",
              "content": {{ toJson $content }}
            },
            "done": {{ if $finishReason }}true{{ else }}false{{ end }}
            {{- if $finishReason }},
            "done_reason": {{ toJson $finishReason }}
            {{- end }}
          }

      # Transform OpenAI non-streaming response to Ollama format
      # Match specifically on completions (has message field, not delta field)
      - match_body:
          object: ^chat\.completion$
        template: |
          {
            "model": {{ toJson .model }},
            "created_at": {{ toJson (isoTime now) }},
            "message": {{ toJson (index .choices 0 "message") }},
            "done": true
            {{- $finishReason := index .choices 0 "finish_reason" }}
            {{- if $finishReason }},
            "done_reason": {{ toJson $finishReason }}
            {{- end }}
            {{- if .usage }}
              {{- if .usage.prompt_tokens }},
            "prompt_eval_count": {{ .usage.prompt_tokens }}
              {{- end }}
              {{- if .usage.completion_tokens }},
            "eval_count": {{ .usage.completion_tokens }}
              {{- end }}
              {{- if .usage.total_tokens }},
            "total_duration": {{ mul .usage.total_tokens 100000000 }}
              {{- end }}
            {{- end }}
          }

  # Model list: Ollama â†’ OpenAI
  - methods: GET
    paths: ^/api/tags$
    target_path: /v1/models

    on_response:
      # Transform OpenAI models response to Ollama tags format
      # Note: Uses realistic placeholder values for fields not available from OpenAI
      - match_body:
          object: list
        template: |
          {
            "models": [
              {{- range $i, $model := .data }}
              {{- if $i }},{{ end }}
              {
                "name": {{ toJson $model.id }},
                "modified_at": {{ toJson (isoTime now) }},
                "size": 4000000000,
                "digest": {{ toJson (uuid) }},
                "details": {
                  "format": "gguf",
                  "family": "llama",
                  "families": null,
                  "parameter_size": "7B",
                  "quantization_level": "Q4_0"
                }
              }
              {{- end }}
            ]
          }

